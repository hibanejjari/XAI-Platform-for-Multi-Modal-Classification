# Unified XAI Platform for Multi-Modal Classification

**Integrating Audio Deepfake Detection and Chest X-ray Analysis with Explainability**
---

## Team ( ESILV A5 : DIA4 )

**Lisa NACCACHE** ‚Ä¢ **Hiba NEJJARI** ‚Ä¢ **Neil MAHCER** ‚Ä¢ **Wendy DUONG** ‚Ä¢ **Cyprien MOUTON**

---

## Table of Contents

- [Overview](#overview)
- [Demo](#demo)
- [Features](#features)
- [Quick Start](#quick-start)
- [Usage](#usage)
- [Project Status](#project-status)
- [Technical Details](#technical-details)
- [Known Issues](#known-issues)
- [AI Usage Declaration](#ai-usage-declaration)
- [References](#references)

---

## Overview
We developed a unified interactive platform that integrates two explainable AI (XAI) systems, audio deepfake detection and lung cancer detection from medical images, into a single interface. The application is organized into two main tabs:
- a **Classification page** where users select the input type (audio or image), choose a pretrained model, and apply an appropriate XAI technique to visualize the explanation alongside the prediction
- an **XAI Comparison page** that enables side-by-side visualization of different XAI methods for the model chosen based on the input -> it's an interface layer that automatically manages compatibility by filtering out XAI techniques that are not applicable to the selected data modality and that allows to see details of the selected method.

The platform supports multiple models and required XAI methods (Grad-CAM, LIME, SHAP) respectively to the input type and model chosen ( VGG16, MobileNet, Custom CNN, FoR Keras (TensorFlow) for audios and XRV DenseNet121 (CheXpert), AlexNet, DenseNet for images) .

The goal of this project is to gain practical experience with Explainable AI (XAI) for audio and image data, while introducing a multi-modal framework designed for future extensibilit. whether its through the models used or to support additional input types .
### Technologies Used

- **Deep Learning Models**: VGG16, MobileNetV2, Custom CNN, DenseNet121, AlexNet  
  *(additional models explored: XRV DenseNet121 (TorchXRayVision), FoR Keras model)*

- **Explainable AI (XAI) Techniques**  : Grad-CAM, LIME, SHAP

- **Programming & Libraries**: Python, PyTorch, TensorFlow/Keras, Pillow, OpenCV (cv2), NumPy, Matplotlib
  
- **Datasets**: Fake-or-Real (Kaggle, audio deepfake), CheXpert (Stanford ML Group chest X-rays)

- **Web Application Framework**: Gradio 4.0+


  

### ü´Å Image: Lung Cancer Detection  
- **Source**: [Lung Cancer Detection](https://github.com/source-repo-2)
- **Dataset**: CheXpert chest X-rays
- **Models**: XRV DenseNet121 (CheXpert), AlexNet, DenseNet
- **XAI**: Grad-CAM ‚úÖ, LIME ‚ö†Ô∏è

### Key Improvements
- ‚úÖ **Unified Interface**: Single Gradio app (migrated from Streamlit for Python 3.13 compatibility)
- ‚úÖ **Dual Framework**: PyTorch + TensorFlow/Keras support
- ‚úÖ **Auto-Compatibility**: XAI methods filtered by input type
- ‚úÖ **Comparison Mode**: Side-by-side XAI visualization

---

## üé• Demo

**[üì∫ Watch Demo Video](YOUR_VIDEO_LINK_HERE)**

---

## ‚ú® Features

| Feature | Audio | Image | Status |
|---------|-------|-------|--------|
| **Classification** | ‚úÖ | ‚úÖ | Working |
| **Grad-CAM** | ‚úÖ | ‚úÖ | Fully functional |
| **SHAP** | ‚úÖ | ‚è≥ | Audio only |
| **LIME** | ‚úÖ | ‚ùå | Image has channel error |
| **Comparison Tab** | ‚úÖ | ‚ö†Ô∏è | Grad-CAM only for images |

---

## üöÄ Quick Start

### Installation

```bash
# Clone repository
git clone https://github.com/YOUR_REPO/unified-xai-platform.git
cd unified-xai-platform

# Install dependencies
pip install -r requirements.txt

# Run application
python app.py
```

**Requirements**: Python 3.8-3.13, 8GB+ RAM

### Configuration

Edit `src/config.py` to customize models, paths, and XAI compatibility:

```python
# Model paths
AUDIO_KERAS_MODEL_PATH = "models/audio/for/audio_classifier.keras"
XRV_IMAGE_WEIGHTS_PATH = "models/image/xrv-densenet121-res224-chex.pth"

# XAI compatibility mapping
XAI_COMPATIBILITY = {
    "Audio": {
        "Custom CNN": ["Grad-CAM", "SHAP", "LIME"],
        "VGG16": ["Grad-CAM", "SHAP", "LIME"],
        # ...
    },
    "Image": {
        "XRV DenseNet121 (CheXpert)": ["Grad-CAM", "LIME"],
        # ...
    }
}
```

---

## üíª Usage

### Classification Tab
1. Select **Audio** or **Image**
2. Upload file (`.wav` or chest X-ray image)
3. Choose model (e.g., VGG16 for audio, XRV DenseNet121 for images)
4. Select XAI method
5. Click **Classify & Explain**

**Working Example**:
```
Audio: Custom CNN + Grad-CAM ‚úÖ
‚Üí Prediction: Real (99.99%), 3-panel visualization
```

### Comparison Tab
1. Upload file
2. Select model
3. Click **Compare XAI Methods**
4. View all compatible methods side-by-side

**Working Example**:
```
Audio: VGG16 ‚Üí Grad-CAM + SHAP + LIME ‚úÖ
Image: XRV DenseNet121 ‚Üí Grad-CAM only ‚ö†Ô∏è (LIME broken)
```

---

## üöß Project Status

### ‚úÖ Working Features

**Audio Classification** (Fully Functional)
- PyTorch models: Custom CNN, VGG16, MobileNetV2 ‚úÖ
- All XAI methods working: Grad-CAM, SHAP, LIME ‚úÖ
- Comparison tab functional ‚úÖ

**Image Classification** (Partial)
- XRV DenseNet121 loads and predicts ‚úÖ
- Grad-CAM works perfectly ‚úÖ
- Shows predictions (generic labels) ‚ö†Ô∏è

### ‚ö†Ô∏è In Progress

**FoR Keras Model** (Audio - TensorFlow)
- File: `audio_classifier.keras` (11 MB)
- Status: Architecture ready, **not trained yet**
- Issue: Random predictions (training required)

**XRV DenseNet121** (Image - PyTorch)  
- File: `xrv-densenet121-res224-chex.pth` (27.8 MB)
- Status: Weights exported, **training incomplete**
- Issues:
  - Generic labels (`Pathology_16` instead of `Cardiomegaly`)
  - LIME fails with channel mismatch

---

## üìä Technical Details

### Design Decisions

**1. Streamlit ‚Üí Gradio Migration**
- Better Python 3.13 support
- Built-in ML components
- Faster development

**2. Dual Framework Architecture**
```
PyTorch Models ‚Üí PyTorch XAI (gradcam.py, shap_xai.py, lime_audio.py)
TensorFlow Models ‚Üí TF XAI (gradcam_tf.py, shap_audio_tf.py, lime_audio_tf.py)
```

**3. Model Management**
- Centralized `ModelManager` with caching
- Lazy loading for memory efficiency
- Automatic framework detection

### XAI Implementation

| Method | Framework | Speed | Accuracy | Status |
|--------|-----------|-------|----------|--------|
| **Grad-CAM** | PyTorch + TF | ‚ö° Fast (1-4s) | ‚≠ê‚≠ê‚≠ê | ‚úÖ All models |
| **LIME** | PyTorch + TF | üêå Slow (10-20s) | ‚≠ê‚≠ê | ‚úÖ Audio, ‚ùå Image |
| **SHAP** | PyTorch + TF | üê¢ Very Slow (30-60s) | ‚≠ê‚≠ê‚≠ê | ‚úÖ Audio only |

### Improvements Over Original Repos

1. ‚úÖ **Unified Platform**: Single interface vs. separate projects
2. ‚úÖ **Auto-Compatibility**: Dynamic XAI filtering
3. ‚úÖ **Dual Framework**: PyTorch + TensorFlow integration
4. ‚úÖ **Better UX**: Modern Gradio UI with comparison mode
5. ‚úÖ **Error Handling**: Comprehensive fallbacks and validation
6. ‚úÖ **Model Caching**: Faster repeated inference

---

## ‚ö†Ô∏è Known Issues

### üî¥ Critical

**Image LIME Channel Error**
```
LIME failed: expected input to have 1 channels, but got 3 channels instead
```
- **Cause**: XRV model expects grayscale, LIME passes RGB
- **Impact**: Image LIME unusable, comparison limited
- **Fix**: In progress (`classify_image_COMPLETE_FIX.py`)

### üü° Medium

**Generic Pathology Labels**
```
Top predicted pathologies:
- Pathology_16: 84.80%  ‚ùå Should be "Cardiomegaly"
- Pathology_7: 80.66%   ‚ùå Should be "Edema"
```
- **Cause**: Model training incomplete, label mismatch
- **Impact**: Unclear which pathology is which
- **Workaround**: Use Grad-CAM for localization

**FoR Keras Untrained**
- Model file present but weights random
- Predictions unreliable
- Requires FoR dataset training

### üü¢ Minor

- Windows asyncio warnings (cosmetic)
- SHAP/LIME slow (reduce samples for speed)

### Fixes Provided

See `EMERGENCY_PATCH.md` for detailed fixes:
1. `classify_audio_CORRECTED.py` - TensorFlow XAI integration
2. `classify_image_COMPLETE_FIX.py` - Label fix + LIME prep
3. `gradcam_tf_FIXED.py` - Keras model building fix
4. `compare_FIXED.py` - Compatibility filtering

---

## ü§ñ AI Usage Declaration

### Generative AI Tools Used

**Tool**: Claude 3.5 Sonnet (Anthropic)

**Purpose**:
- ‚úÖ Code debugging and error resolution
- ‚úÖ XAI implementation guidance (Grad-CAM, LIME, SHAP)
- ‚úÖ Framework integration (PyTorch ‚Üî TensorFlow)
- ‚úÖ Documentation writing
- ‚úÖ Bug fix generation (channel mismatch, label errors)

**What We Did Ourselves**:
- ‚úÖ Project architecture design
- ‚úÖ Model selection and integration decisions
- ‚úÖ UI/UX design and workflow
- ‚úÖ Testing and validation
- ‚úÖ Dataset understanding and preprocessing

**Transparency Statement**: 
All AI-generated code was reviewed, tested, and adapted to our specific requirements. We understand the implementation and can explain all design decisions.

---

## üìö References

### Original Repositories
1. [Deepfake Audio Detector with XAI](https://github.com/source-audio-repo)
2. [Lung Cancer Detection](https://github.com/source-image-repo)

### Datasets
- **FoR (Fake-or-Real)**: Audio deepfake dataset
- **CheXpert**: 224,316 chest X-rays with 14 pathology labels

### XAI Papers
- **Grad-CAM**: Selvaraju et al. (ICCV 2017) - [arXiv:1610.02391](https://arxiv.org/abs/1610.02391)
- **LIME**: Ribeiro et al. (KDD 2016) - [arXiv:1602.04938](https://arxiv.org/abs/1602.04938)
- **SHAP**: Lundberg & Lee (NeurIPS 2017) - [arXiv:1705.07874](https://arxiv.org/abs/1705.07874)

### Libraries
- **Gradio**: Web UI framework
- **TorchXRayVision**: Medical imaging models
- **PyTorch** + **TensorFlow**: Deep learning frameworks

---

## üìÅ Project Structure

```
unified-xai-platform/
‚îú‚îÄ‚îÄ app.py                    # Entry point
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ config.py            # ‚öôÔ∏è Configuration
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing/       # Audio/image preprocessing
‚îÇ   ‚îú‚îÄ‚îÄ pipelines/           # Classification + XAI workflows
‚îÇ   ‚îú‚îÄ‚îÄ xai/                 # Grad-CAM, LIME, SHAP (PyTorch + TF)
‚îÇ   ‚îî‚îÄ‚îÄ ui/                  # Gradio interface
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ audio/for/           # FoR Keras (11 MB, untrained)
‚îÇ   ‚îú‚îÄ‚îÄ image/               # XRV DenseNet121 (27.8 MB, partial)
‚îÇ   ‚îú‚îÄ‚îÄ audio_models.py      # PyTorch audio models
‚îÇ   ‚îú‚îÄ‚îÄ image_models.py      # PyTorch image models
‚îÇ   ‚îî‚îÄ‚îÄ manager.py           # Model loading
‚îî‚îÄ‚îÄ tools/                   # Model generation scripts
```

---

## üéØ Future Work

**Immediate**:
- [ ] Train FoR Keras on FoR dataset
- [ ] Complete XRV DenseNet121 training
- [ ] Fix image LIME channel issue

**Planned**:
- [ ] Add more XAI methods (Integrated Gradients, SmoothGrad)
- [ ] Batch processing mode
- [ ] Export to PDF reports
- [ ] Docker deployment

---

## üìÑ License

MIT License - Copyright (c) 2026 DIA4 Team

---

<div align="center">


- **Datasets**  :
- **Fake-or-Real (FoR)**: Audio deepfake detection dataset used for Keras model training  
- **CheXpert**: Chest X-ray pathology detection dataset (224,316 images, 14 pathology labels) used with XRV DenseNet121
- 
- **Development & Sources**  
- Deepfake Audio Detection with XAI (GitHub): https://github.com/Guri10/Deepfake-Audio-Detection-with-XAI  
- Lung Cancer Detection (GitHub): https://github.com/schaudhuri16/LungCancerDetection  
- TorchXRayVision: https://github.com/mlmed/torchxrayvision  
- FoR Dataset (Kaggle): https://www.kaggle.com/datasets/mohammedabdeldayem/the-fake-or-real-dataset  
- CheXpert Dataset (Stanford ML Group): https://www.kaggle.com/datasets/ashery/chexpert
**Made with ‚ù§Ô∏è by DIA4**

*Explainable AI for Audio & Medical Imaging*

[![Python](https://img.shields.io/badge/Python-3.8--3.13-blue.svg)](https://www.python.org/)
[![Gradio](https://img.shields.io/badge/Gradio-4.0+-orange.svg)](https://gradio.app/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.13+-orange.svg)](https://tensorflow.org/)

[‚¨Ü Back to Top](#-unified-xai-platform-for-multi-modal-classification)

</div>
